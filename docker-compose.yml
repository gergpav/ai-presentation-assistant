services:
  # PostgreSQL база данных
  db:
    image: postgres:16-alpine
    container_name: ai-presentation-db
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-ai_presentation}
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ai-presentation-network
    restart: unless-stopped

  # Приложение (Frontend + Backend в одном контейнере)
  app:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        VITE_API_BASE_URL: ${VITE_API_BASE_URL:-/api}
    container_name: ai-presentation-app
    dns:
      - 8.8.8.8
      - 8.8.4.4
    environment:
      DATABASE_URL_ASYNC: postgresql+asyncpg://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@db:5432/${POSTGRES_DB:-ai_presentation}
      DATABASE_URL_SYNC: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@db:5432/${POSTGRES_DB:-ai_presentation}
      JWT_SECRET_KEY: ${JWT_SECRET_KEY}
      JWT_ALGORITHM: ${JWT_ALGORITHM:-HS256}
      ACCESS_TOKEN_EXPIRE_MINUTES: ${ACCESS_TOKEN_EXPIRE_MINUTES:-1440}
      LLM_MODEL: ${LLM_MODEL:-Qwen/Qwen2.5-3B-Instruct}
      MAX_NEW_TOKENS: ${MAX_NEW_TOKENS:-250}
      TEMPERATURE: ${TEMPERATURE:-0.3}
      USE_QUANTIZATION: ${USE_QUANTIZATION:-false}
      PORT: 8001
      # Таймаут генерации контента (в секундах, по умолчанию 10 минут)
      LLM_GENERATION_TIMEOUT_SEC: ${LLM_GENERATION_TIMEOUT_SEC:-600}
      # Настройки HuggingFace Hub для надежной загрузки моделей
      HF_HUB_DISABLE_TELEMETRY: "1"
      HF_HUB_ENABLE_HF_TRANSFER: "0"
      HF_HUB_DOWNLOAD_TIMEOUT: "600"
      REQUESTS_TIMEOUT: "600"
      # Настройки GPU/CUDA
      FORCE_CPU: ${FORCE_CPU:-false}
      STABLE_DIFFUSION_MODEL_ID: ${STABLE_DIFFUSION_MODEL_ID:-runwayml/stable-diffusion-v1-5}
      STABLE_DIFFUSION_DEVICE: ${STABLE_DIFFUSION_DEVICE:-cuda}
      STABLE_DIFFUSION_STEPS: ${STABLE_DIFFUSION_STEPS:-30}
      STABLE_DIFFUSION_GUIDANCE_SCALE: ${STABLE_DIFFUSION_GUIDANCE_SCALE:-7.5}
      STABLE_DIFFUSION_WIDTH: ${STABLE_DIFFUSION_WIDTH:-512}
      STABLE_DIFFUSION_HEIGHT: ${STABLE_DIFFUSION_HEIGHT:-512}
    ports:
      - "${APP_PORT:-8001}:8001"  # Backend API
      - "${FRONTEND_PORT:-80}:80"  # Frontend (nginx)
    volumes:
      - ./storage:/app/storage
      # Монтирование кода для разработки отключено в production
      # Раскомментируйте следующую строку для разработки:
      # - ./app:/app/app:ro
    depends_on:
      db:
        condition: service_healthy
    networks:
      - ai-presentation-network
    restart: unless-stopped
    # GPU поддержка для использования CUDA
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Worker для фоновых задач
  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-presentation-worker
    dns:
      - 8.8.8.8
      - 8.8.4.4
    environment:
      DATABASE_URL_ASYNC: postgresql+asyncpg://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@db:5432/${POSTGRES_DB:-ai_presentation}
      DATABASE_URL_SYNC: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@db:5432/${POSTGRES_DB:-ai_presentation}
      JWT_SECRET_KEY: ${JWT_SECRET_KEY}
      LLM_MODEL: ${LLM_MODEL:-Qwen/Qwen2.5-3B-Instruct}
      MAX_NEW_TOKENS: ${MAX_NEW_TOKENS:-250}
      TEMPERATURE: ${TEMPERATURE:-0.3}
      USE_QUANTIZATION: ${USE_QUANTIZATION:-false}
      RUN_WORKER: "true"
      # Таймаут генерации контента (в секундах, по умолчанию 10 минут)
      LLM_GENERATION_TIMEOUT_SEC: ${LLM_GENERATION_TIMEOUT_SEC:-600}
      # Настройки HuggingFace Hub для надежной загрузки моделей
      HF_HUB_DISABLE_TELEMETRY: "1"
      HF_HUB_ENABLE_HF_TRANSFER: "0"
      HF_HUB_DOWNLOAD_TIMEOUT: "600"
      REQUESTS_TIMEOUT: "600"
      # Настройки GPU/CUDA
      FORCE_CPU: ${FORCE_CPU:-false}
      STABLE_DIFFUSION_MODEL_ID: ${STABLE_DIFFUSION_MODEL_ID:-runwayml/stable-diffusion-v1-5}
      STABLE_DIFFUSION_DEVICE: ${STABLE_DIFFUSION_DEVICE:-cuda}
      STABLE_DIFFUSION_STEPS: ${STABLE_DIFFUSION_STEPS:-30}
      STABLE_DIFFUSION_GUIDANCE_SCALE: ${STABLE_DIFFUSION_GUIDANCE_SCALE:-7.5}
      STABLE_DIFFUSION_WIDTH: ${STABLE_DIFFUSION_WIDTH:-512}
      STABLE_DIFFUSION_HEIGHT: ${STABLE_DIFFUSION_HEIGHT:-512}
    volumes:
      - ./storage:/app/storage
    depends_on:
      - db
      - app
    entrypoint: ["/docker-entrypoint.sh", "worker"]
    networks:
      - ai-presentation-network
    restart: unless-stopped
    # GPU поддержка для использования CUDA
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

volumes:
  postgres_data:

networks:
  ai-presentation-network:
    driver: bridge
