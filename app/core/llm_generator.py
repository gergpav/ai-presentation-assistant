import torch
from transformers import pipeline
from app.config import settings
import logging
from typing import Dict, Any
import re

logger = logging.getLogger(__name__)


class ContentGenerator:
    def __init__(self):
        self.generator = None
        self.tokenizer = None
        self.model = None
        self.is_loaded = False
        self._load_rugpt3_model()

    def _load_rugpt3_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ rugpt3small"""
        try:
            logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω–æ–π –º–æ–¥–µ–ª–∏: {settings.LLM_MODEL}")

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º pipeline –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã
            self.generator = pipeline(
                "text-generation",
                model=settings.LLM_MODEL,
                tokenizer=settings.LLM_MODEL,
                torch_dtype=torch.float32,
                device=-1,  # CPU
                max_length=settings.MAX_NEW_TOKENS,
                temperature=settings.TEMPERATURE,
                top_p=settings.TOP_P,
                do_sample=settings.DO_SAMPLE,
                repetition_penalty=settings.REPETITION_PENALTY,
            )

            self.is_loaded = True
            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {settings.LLM_MODEL} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            self._enable_test_mode()

    def _enable_test_mode(self):
        """–í–∫–ª—é—á–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º"""
        logger.info("üîÑ –ê–∫—Ç–∏–≤–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞")
        self.is_loaded = True
        self.test_mode = True

    @staticmethod
    def _build_russian_prompt(slide_type: str, context: str, audience: str) -> str:
        """–°—Ç—Ä–æ–∏—Ç —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è rugpt3"""

        prompts = {
            "title": f"–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —É–±–µ–¥–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}\n\n–ó–∞–≥–æ–ª–æ–≤–æ–∫:",
            "problem": f"–û–ø–∏—à–∏ –ø—Ä–æ–±–ª–µ–º—É, –∫–æ—Ç–æ—Ä—É—é —Ä–µ—à–∞–µ—Ç —ç—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç, –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}\n\n–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:",
            "solution": f"–û–ø–∏—à–∏ —Ä–µ—à–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –ø—Ä–æ–µ–∫—Ç, –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}\n\n–û–ø–∏—Å–∞–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è:",
            "market": f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä—ã–Ω–æ–∫ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —ç—Ç–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ –≤ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}\n\n–ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞:",
            "finance": f"–û–ø–∏—à–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}\n\n–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏:",
            "team": f"–û–ø–∏—à–∏ –∫–æ–º–∞–Ω–¥—É –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}\n\n–û–ø–∏—Å–∞–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã:",
            "summary": f"–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –∑–∞–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Å–ª–∞–π–¥–∞ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}\n\n–†–µ–∑—é–º–µ –ø—Ä–æ–µ–∫—Ç–∞:"
        }

        return prompts.get(slide_type, f"–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è —Å–ª–∞–π–¥–∞ '{slide_type}'. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}\n\n–ö–æ–Ω—Ç–µ–Ω—Ç:")

    @staticmethod
    def _clean_generated_text(text: str, prompt: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç"""
        # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–º–ø—Ç
        if text.startswith(prompt):
            text = text[len(prompt):].strip()

        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏
        text = text.strip('"\'').strip()

        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–∫–æ–Ω—á–µ–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentences = re.split(r'[.!?]', text)
        if len(sentences) > 1:
            text = sentences[0] + '.'

        # –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Ñ—Ä–∞–∑—ã
        words = text.split()
        if len(words) > 2 and words[0] == words[1]:
            text = ' '.join(words[1:])

        return text[:400]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É

    def generate_slide_content(self, slide_type: str, context: str, audience: str = "–∏–Ω–≤–µ—Å—Ç–æ—Ä—ã") -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è —Å–ª–∞–π–¥–∞"""

        if not self.is_loaded:
            return {
                "content": f"[–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞] –ö–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è —Å–ª–∞–π–¥–∞ '{slide_type}'",
                "status": "error",
                "error": "LLM –º–æ–¥–µ–ª—å –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞"
            }

        # –ï—Å–ª–∏ –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
        if hasattr(self, 'test_mode') and self.test_mode:
            return self._generate_test_content(slide_type, context, audience)

        try:
            # –°—Ç—Ä–æ–∏–º —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            prompt = self._build_russian_prompt(slide_type, context, audience)

            logger.debug(f"–ü—Ä–æ–º–ø—Ç –¥–ª—è {slide_type}: {prompt[:100]}...")

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
            result = self.generator(
                prompt,
                max_length=settings.MAX_NEW_TOKENS,
                num_return_sequences=1,
                pad_token_id=self.generator.tokenizer.eos_token_id,
            )

            generated_text = result[0]['generated_text']
            cleaned_text = self._clean_generated_text(generated_text, prompt)

            logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è {slide_type}")

            return {
                "content": cleaned_text,
                "slide_type": slide_type,
                "audience": audience,
                "status": "success"
            }

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è {slide_type}: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
            return self._generate_test_content(slide_type, context, audience)

    @staticmethod
    def _generate_test_content(slide_type: str, context: str, audience: str) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        test_contents = {
            "title": "üöÄ AI Presentation Assistant - –ò–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã—Ö –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π",
            "problem": "üìä –ü—Ä–æ–±–ª–µ–º–∞: –ö–æ–º–∞–Ω–¥—ã —Ç—Ä–∞—Ç—è—Ç 40+ —á–∞—Å–æ–≤ –Ω–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –∫–∞–∂–¥–æ–π –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏. –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ä–µ—à–µ–Ω–∏—è –Ω–µ –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –ø–æ–ª–Ω–æ–π –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞.",
            "solution": "üí° –†–µ—à–µ–Ω–∏–µ: AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏. –ö–ª—é—á–µ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏: –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞, –∞–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ –∞—É–¥–∏—Ç–æ—Ä–∏—é.",
            "market": "üåç –†—ã–Ω–æ–∫: –û–±—ä–µ–º –º–∏—Ä–æ–≤–æ–≥–æ —Ä—ã–Ω–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç $500 –º–ª–Ω –≤ –≥–æ–¥ —Å —Ä–æ—Å—Ç–æ–º 15% –µ–∂–µ–≥–æ–¥–Ω–æ. –¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è: —Å—Ç–∞—Ä—Ç–∞–ø—ã, –≤–µ–Ω—á—É—Ä–Ω—ã–µ —Ñ–æ–Ω–¥—ã, –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –æ—Ç–¥–µ–ª—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏.",
            "finance": "üí∞ –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏: –ü–ª–∞–Ω–∏—Ä—É–µ–º–∞—è –≤—ã—Ä—É—á–∫–∞ –≤ –ø–µ—Ä–≤—ã–π –≥–æ–¥ - $2 –º–ª–Ω. Customer Acquisition Cost: $500. Lifetime Value: $5000. –ü–µ—Ä–∏–æ–¥ –æ–∫—É–ø–∞–µ–º–æ—Å—Ç–∏: 18 –º–µ—Å—è—Ü–µ–≤. EBITDA margin: 25%.",
            "team": "üë• –ö–æ–º–∞–Ω–¥–∞: –û—Å–Ω–æ–≤–∞—Ç–µ–ª–∏ —Å –≥–ª—É–±–æ–∫–∏–º –æ–ø—ã—Ç–æ–º –≤ AI –∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–∏—Ä–µ–∫—Ç–æ—Ä - 10 –ª–µ—Ç –≤ machine learning. CEO - –±—ã–≤—à–∏–π –º–µ–Ω–µ–¥–∂–µ—Ä –≤–µ–Ω—á—É—Ä–Ω–æ–≥–æ —Ñ–æ–Ω–¥–∞ —Å –æ–ø—ã—Ç–æ–º –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏—è $50M+.",
            "summary": "‚úÖ –†–µ–∑—é–º–µ: –ü—Ä–æ–µ–∫—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ —Å —á–µ—Ç–∫–æ–π –±–∏–∑–Ω–µ—Å-–º–æ–¥–µ–ª—å—é –∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–º —Ä—ã–Ω–æ—á–Ω—ã–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º. –°–∏–ª—å–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞, –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω–∞—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è –∏ —Ä–∞—Å—Ç—É—â–∏–π —Ä—ã–Ω–æ–∫ —Å–æ–∑–¥–∞—é—Ç —É—Å–ª–æ–≤–∏—è –¥–ª—è —É—Å–ø–µ—à–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏."
        }

        content = test_contents.get(
            slide_type,
            f"üìù –ö–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è —Å–ª–∞–π–¥–∞ '{slide_type}'. –ê—É–¥–∏—Ç–æ—Ä–∏—è: {audience}. –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {context[:100]}..."
        )

        return {
            "content": content,
            "slide_type": slide_type,
            "audience": audience,
            "status": "success",
            "test_mode": True
        }

    def health_check(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –º–æ–¥–µ–ª–∏"""
        if not self.is_loaded:
            return {"status": "not_loaded", "model": settings.LLM_MODEL}

        if hasattr(self, 'test_mode') and self.test_mode:
            return {
                "status": "test_mode",
                "model": "test_data",
                "message": "–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ"
            }

        try:
            # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏
            test_prompt = "–¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å:"
            test_result = self.generator(test_prompt, max_length=20, num_return_sequences=1)

            return {
                "status": "healthy",
                "model": settings.LLM_MODEL,
                "license": "open-source",
                "language": "russian",
                "test_passed": len(test_result[0]['generated_text']) > 0
            }
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "model": settings.LLM_MODEL
            }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
content_generator = ContentGenerator()