import torch
from transformers import pipeline
from app.config import settings
import logging
from typing import Dict, Any
import re

logger = logging.getLogger(__name__)


class ContentGenerator:
    def __init__(self):
        self.generator = None
        self.is_loaded = False
        self._load_qwen_model()

    def _load_qwen_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ Qwen –º–æ–¥–µ–ª–∏"""
        try:
            logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ Qwen –º–æ–¥–µ–ª–∏: {settings.LLM_MODEL}")

            # Qwen –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥
            self.generator = pipeline(
                "text-generation",
                model=settings.LLM_MODEL,
                torch_dtype=torch.float32,
                device_map="auto",  # Qwen –ª—É—á—à–µ —Å auto device map
                max_new_tokens=settings.MAX_NEW_TOKENS,
                temperature=settings.TEMPERATURE,
                top_p=settings.TOP_P,
                do_sample=settings.DO_SAMPLE,
            )

            self.is_loaded = True
            logger.info(f"‚úÖ Qwen –º–æ–¥–µ–ª—å {settings.LLM_MODEL} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Qwen –º–æ–¥–µ–ª–∏: {e}")
            self._load_fallback_model()

    def _load_fallback_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ fallback –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ Qwen –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è"""
        try:
            logger.info("–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ GPT-2 –∫–∞–∫ fallback...")

            self.generator = pipeline(
                "text-generation",
                model="gpt2",
                max_new_tokens=settings.MAX_NEW_TOKENS,
                temperature=settings.TEMPERATURE,
            )

            self.is_loaded = True
            logger.info("‚úÖ GPT-2 –∑–∞–≥—Ä—É–∂–µ–Ω –∫–∞–∫ fallback –º–æ–¥–µ–ª—å")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ fallback –º–æ–¥–µ–ª–∏: {e}")
            self._enable_test_mode()

    def _enable_test_mode(self):
        """–í–∫–ª—é—á–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º"""
        logger.info("üîÑ –ê–∫—Ç–∏–≤–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞")
        self.is_loaded = True
        self.test_mode = True

    def _build_qwen_prompt(self, slide_type: str, context: str, audience: str) -> str:
        """–°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ Qwen Chat"""

        # Qwen –∏—Å–ø–æ–ª—å–∑—É–µ—Ç chat-—Ñ–æ—Ä–º–∞—Ç —Å —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
        system_prompt = """–¢—ã - AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã—Ö –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π. 
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è —Å–ª–∞–π–¥–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
–ë—É–¥—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–º, —É–±–µ–¥–∏—Ç–µ–ª—å–Ω—ã–º –∏ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–º."""

        user_prompts = {
            "title": f"–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —É–±–µ–¥–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}",
            "problem": f"–û–ø–∏—à–∏ –ø—Ä–æ–±–ª–µ–º—É, –∫–æ—Ç–æ—Ä—É—é —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–µ–∫—Ç, –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}",
            "solution": f"–û–ø–∏—à–∏ —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}",
            "market": f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä—ã–Ω–æ–∫ –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}",
            "finance": f"–û–ø–∏—à–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}",
            "team": f"–û–ø–∏—à–∏ –∫–æ–º–∞–Ω–¥—É –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}",
            "summary": f"–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}"
        }

        user_message = user_prompts.get(slide_type,
                                        f"–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è —Å–ª–∞–π–¥–∞ '{slide_type}'. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}")

        # Qwen chat format
        prompt = f"<|im_start|>system\n{system_prompt}<|im_end|>\n<|im_start|>user\n{user_message}<|im_end|>\n<|im_start|>assistant\n"

        return prompt

    def _clean_generated_text(self, text: str, prompt: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è Qwen"""
        # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–º–ø—Ç –∏ —Å–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã Qwen
        if prompt in text:
            text = text.replace(prompt, "")

        # –£–¥–∞–ª—è–µ–º Qwen-specific tokens
        text = text.replace("<|im_start|>", "").replace("<|im_end|>", "").replace("assistant", "")

        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
        text = re.sub(r'\n+', '\n', text.strip())
        text = re.sub(r' +', ' ', text)

        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ —Ä–∞–∑—É–º–Ω–æ–π –¥–ª–∏–Ω—ã
        return text[:800].strip()

    def generate_slide_content(self, slide_type: str, context: str, audience: str = "–∏–Ω–≤–µ—Å—Ç–æ—Ä—ã") -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è —Å–ª–∞–π–¥–∞ —Å Qwen"""

        if not self.is_loaded:
            return {
                "content": f"[–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞] –ö–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è —Å–ª–∞–π–¥–∞ '{slide_type}'",
                "status": "error",
                "error": "LLM –º–æ–¥–µ–ª—å –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞"
            }

        # –ï—Å–ª–∏ –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
        if hasattr(self, 'test_mode') and self.test_mode:
            return self._generate_test_content(slide_type, context, audience)

        try:
            # –°—Ç—Ä–æ–∏–º –ø—Ä–æ–º–ø—Ç –¥–ª—è Qwen
            prompt = self._build_qwen_prompt(slide_type, context[:400], audience)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç

            logger.debug(f"–ü—Ä–æ–º–ø—Ç –¥–ª—è {slide_type}: {prompt[:200]}...")

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å Qwen
            result = self.generator(
                prompt,
                max_new_tokens=settings.MAX_NEW_TOKENS,
                num_return_sequences=1,
                pad_token_id=self.generator.tokenizer.eos_token_id,
                truncation=True,
                return_full_text=False,
            )

            generated_text = result[0]['generated_text']
            cleaned_text = self._clean_generated_text(generated_text, prompt)

            logger.info(f"‚úÖ Qwen —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è {slide_type}")

            return {
                "content": cleaned_text,
                "slide_type": slide_type,
                "audience": audience,
                "status": "success"
            }

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Qwen –¥–ª—è {slide_type}: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
            return self._generate_test_content(slide_type, context, audience)

    def _generate_test_content(self, slide_type: str, context: str, audience: str) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        test_contents = {
            "title": "üöÄ AI Presentation Assistant - –ò–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞",
            "problem": "üìä –ü—Ä–æ–±–ª–µ–º–∞: –ö–æ–º–∞–Ω–¥—ã —Ç—Ä–∞—Ç—è—Ç 40+ —á–∞—Å–æ–≤ –Ω–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã—Ö –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π",
            "solution": "üí° –†–µ—à–µ–Ω–∏–µ: AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π",
            "market": "üåç –†—ã–Ω–æ–∫: $500 –º–ª–Ω –≤ –≥–æ–¥ —Å —Ä–æ—Å—Ç–æ–º 15% –µ–∂–µ–≥–æ–¥–Ω–æ",
            "finance": "üí∞ –§–∏–Ω–∞–Ω—Å—ã: –í—ã—Ä—É—á–∫–∞ $2 –º–ª–Ω –≤ –ø–µ—Ä–≤—ã–π –≥–æ–¥, –æ–∫—É–ø–∞–µ–º–æ—Å—Ç—å 18 –º–µ—Å—è—Ü–µ–≤",
            "team": "üë• –ö–æ–º–∞–Ω–¥–∞: –û–ø—ã—Ç–Ω—ã–µ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—ã –≤ AI –∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö",
            "summary": "‚úÖ –†–µ–∑—é–º–µ: –ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–µ–∫—Ç —Å —á–µ—Ç–∫–æ–π –±–∏–∑–Ω–µ—Å-–º–æ–¥–µ–ª—å—é –∏ —Å–∏–ª—å–Ω–æ–π –∫–æ–º–∞–Ω–¥–æ–π"
        }

        content = test_contents.get(
            slide_type,
            f"–ö–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è —Å–ª–∞–π–¥–∞ '{slide_type}'. –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context[:100]}..."
        )

        return {
            "content": content,
            "slide_type": slide_type,
            "audience": audience,
            "status": "success",
            "test_mode": True
        }

    def health_check(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –º–æ–¥–µ–ª–∏"""
        if not self.is_loaded:
            return {"status": "not_loaded", "model": settings.LLM_MODEL}

        if hasattr(self, 'test_mode') and self.test_mode:
            return {
                "status": "test_mode",
                "model": "test_data",
                "message": "–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ"
            }

        try:
            # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç—ã Qwen
            test_prompt = "<|im_start|>system\n–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.<|im_end|>\n<|im_start|>user\n–ü—Ä–∏–≤–µ—Ç!<|im_end|>\n<|im_start|>assistant\n"
            test_result = self.generator(test_prompt, max_new_tokens=10, num_return_sequences=1)

            return {
                "status": "healthy",
                "model": settings.LLM_MODEL,
                "license": "open-source",
                "provider": "Qwen",
                "test_passed": len(test_result[0]['generated_text']) > 0
            }
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "model": settings.LLM_MODEL
            }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
content_generator = ContentGenerator()