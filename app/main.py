# ÐšÐ Ð˜Ð¢Ð˜Ð§ÐÐž: Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð”Ðž Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð° PyTorch/transformers
# Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´Ð¾Ñ‚Ð²Ñ€Ð°Ñ‰ÐµÐ½Ð¸Ñ Ð¿Ð¾Ð¿Ñ‹Ñ‚Ð¾Ðº Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ CUDA
import os

# ÐŸÑ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð¾Ñ‚ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ CUDA (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ true Ð´Ð»Ñ Ð¸Ð·Ð±ÐµÐ¶Ð°Ð½Ð¸Ñ Ð¾ÑˆÐ¸Ð±Ð¾Ðº)
force_cpu = os.getenv("FORCE_CPU", "true").lower() == "true"
if force_cpu:
    os.environ["CUDA_VISIBLE_DEVICES"] = ""  # Ð¡ÐºÑ€Ñ‹Ð²Ð°ÐµÐ¼ GPU Ð¾Ñ‚ Ð²ÑÐµÑ… Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐº
    os.environ["TOKENIZERS_PARALLELISM"] = "false"

from contextlib import asynccontextmanager
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import logging
from app.api.auth import router as auth_router
from app.api.projects import router as projects_router
from app.api.slides import router as slides_router
from app.api.generate import router as generate_router
from app.api.documents import router as documents_router
from app.api.export import router as export_router
from app.api.jobs import router as jobs_router
from app.api.download import router as download_router
from app.api.templates import router as templates_router
from app.core.embeddings import document_index, model
from app.core.llm_generator import content_generator

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    logger.info("ðŸš€ AI Presentation Assistant starting up...")
    health = content_generator.health_check()
    logger.info(f"LLM Model status: {health}")
    yield
    # Shutdown
    logger.info("ðŸ›‘ AI Presentation Assistant shutting down...")


app = FastAPI(
    title="AI Presentation Assistant",
    description="Ð¡ÐµÑ€Ð²Ð¸Ñ Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð½Ð²ÐµÑÑ‚Ð¸Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ñ… Ð¿Ñ€ÐµÐ·ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¹",
    version="1.0.0",
    lifespan=lifespan
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://localhost:3000", "http://127.0.0.1:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    # ÐÑƒÐ¶Ð½Ð¾, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ñ„Ñ€Ð¾Ð½Ñ‚ÐµÐ½Ð´ Ð¼Ð¾Ð³ Ð¿Ñ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ Content-Disposition Ð¸ Ð²Ð·ÑÑ‚ÑŒ filename Ñ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸ÐµÐ¼
    expose_headers=["Content-Disposition"],
)

# Auth
app.include_router(auth_router)

# Projects
app.include_router(projects_router)

# Slides
app.include_router(slides_router)
app.include_router(generate_router)
app.include_router(documents_router)

# Jobs
app.include_router(jobs_router)

# Export
app.include_router(export_router)
app.include_router(download_router)

# Templates
app.include_router(templates_router)


@app.get("/")
def root():
    return {
        "message": "AI Presentation Assistant is running ðŸš€",
    }


@app.get("/health")
def health_check():
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ Ð²ÑÐµÑ… ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¾Ð² ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹"""
    model_health = content_generator.health_check()

    # Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° document_index
    try:
        documents_loaded = len(document_index.documents) > 0
        documents_count = len(document_index.documents)
        index_built = document_index.is_built
    except Exception as e:
        logger.error(f"Error checking document index: {e}")
        documents_loaded = False
        documents_count = 0
        index_built = False

    logger.info(f"Model device: {model.device}")

    return {
        "status": "healthy" if model_health["status"] in ["healthy", "loaded"] else "degraded",
        "components": {
            "llm_model": model_health,
            "document_index": {
                "loaded": documents_loaded,
                "documents_count": documents_count,
                "index_built": index_built
            }
        }
    }