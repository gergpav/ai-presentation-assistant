# app/workers/runner.py
# ÐšÐ Ð˜Ð¢Ð˜Ð§ÐÐž: Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð”Ðž Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð° PyTorch/transformers
import os

# ÐŸÑ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð¾Ñ‚ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ CUDA (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ true Ð´Ð»Ñ Ð¸Ð·Ð±ÐµÐ¶Ð°Ð½Ð¸Ñ Ð¾ÑˆÐ¸Ð±Ð¾Ðº)
force_cpu = os.getenv("FORCE_CPU", "true").lower() == "true"
if force_cpu:
    os.environ["CUDA_VISIBLE_DEVICES"] = ""  # Ð¡ÐºÑ€Ñ‹Ð²Ð°ÐµÐ¼ GPU Ð¾Ñ‚ Ð²ÑÐµÑ… Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐº
    os.environ["TOKENIZERS_PARALLELISM"] = "false"

import asyncio
import logging
import uuid
from sqlalchemy.orm import Session, joinedload
from pathlib import Path
from typing import Optional, List

import pdfplumber
from docx import Document as DocxDocument
from pptx import Presentation as PptxPresentation
import pandas as pd

from sqlalchemy import select, desc
from sqlalchemy.ext.asyncio import AsyncSession

from app.db.session import AsyncSessionLocal
from app.db.models.job import Job
from app.db.models.project import Project
from app.db.models.slide import Slide
from app.db.models.slide_content import SlideContent
from app.db.models.slide_document import SlideDocument
from app.db.models.file import File
from app.db.models.enums import JobStatus, JobType, SlideStatus, FileKind
from app.db.models import Template

from app.core.llm_generator import content_generator
from app.core.embeddings import DocumentIndex

from app.core.pptx_builder import PresentationBuilder
from app.core.pdf_builder import slides_to_pdf_bytes
from app.core.image_generator import image_generator
from app.utils.helpers import SlideExport
from app.config import settings

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

POLL_INTERVAL_SEC = 1.0
STORAGE_DIR = Path("storage")
STORAGE_DIR.mkdir(exist_ok=True)

# Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐµÐ¼Ð°Ñ„Ð¾Ñ€ Ð´Ð»Ñ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð²Ñ‹Ð·Ð¾Ð²Ð¾Ð² Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸
# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ÑÑ Ð² worker_loop()
_llm_generation_semaphore: Optional[asyncio.Semaphore] = None


# ----------------------------
# Helpers: SlideContent text field (Ð¿Ð¾Ð´ Ñ€Ð°Ð·Ð½Ñ‹Ðµ Ð¸Ð¼ÐµÐ½Ð° ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº)
# ----------------------------
def _sc_get_text(sc: SlideContent | None) -> str:
    if sc is None:
        return ""
    if hasattr(sc, "content_text"):
        return sc.content_text or ""
    if hasattr(sc, "content"):
        # SlideContent.content ÑÑ‚Ð¾ JSON Ð¿Ð¾Ð»Ðµ (dict)
        if isinstance(sc.content, dict):
            return sc.content.get("text", "") or ""
        elif isinstance(sc.content, str):
            return sc.content or ""
        return ""
    if hasattr(sc, "text"):
        return sc.text or ""
    return ""


def _sc_set_text(sc: SlideContent, text: str) -> None:
    """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ñ‚ÐµÐºÑÑ‚ Ð² SlideContent.content ÐºÐ°Ðº JSON"""
    if hasattr(sc, "content_text"):
        sc.content_text = text
        return
    if hasattr(sc, "content"):
        # SlideContent.content ÑÑ‚Ð¾ JSON Ð¿Ð¾Ð»Ðµ, ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÐºÐ°Ðº ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ
        sc.content = {"text": text}
        return
    if hasattr(sc, "text"):
        sc.text = text
        return
    raise RuntimeError("SlideContent: Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð¿Ð¾Ð»Ðµ Ð´Ð»Ñ Ñ‚ÐµÐºÑÑ‚Ð° (content_text/content/text)")


# ----------------------------
# Helpers: parsing files from path (pptx/docx/xlsx/pdf)
# ----------------------------
async def _parse_text_from_path(path: str) -> str:
    """
    ÐœÐ¸Ð½Ð¸-Ð¿Ð°Ñ€ÑÐµÑ€ "ÐºÐ°Ðº ÐµÑÑ‚ÑŒ" Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°.
    Ð¥Ñ€Ð°Ð½Ð¸Ñ‚ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð² SlideDocument.parsed_text, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð¿Ð°Ñ€ÑÐ¸Ñ‚ÑŒ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾.
    """
    p = Path(path)
    if not p.exists():
        return ""

    ext = p.suffix.lower()

    try:
        if ext == ".pdf":
            text = ""
            with pdfplumber.open(str(p)) as pdf:
                for page in pdf.pages:
                    text += (page.extract_text() or "") + "\n"
            return text.strip()

        if ext == ".docx":
            doc = DocxDocument(str(p))
            parts = [par.text for par in doc.paragraphs if par.text]
            return "\n".join(parts).strip()

        if ext == ".pptx":
            pres = PptxPresentation(str(p))
            parts: list[str] = []
            for slide in pres.slides:
                for shape in slide.shapes:
                    if hasattr(shape, "text") and shape.text:
                        parts.append(shape.text)
            return "\n".join(parts).strip()

        if ext in (".xlsx", ".xls"):
            # Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð²ÑÐµ Ð»Ð¸ÑÑ‚Ñ‹, ÑÐºÐ»ÐµÐ¸Ð²Ð°ÐµÐ¼ ÐºÐ°Ðº Ñ‚ÐµÐºÑÑ‚Ð¾Ð²ÑƒÑŽ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ
            xls = pd.ExcelFile(str(p))
            out: list[str] = []
            for sheet in xls.sheet_names:
                df = xls.parse(sheet)
                out.append(f"=== {sheet} ===")
                out.append(df.to_string(index=False))
            return "\n".join(out).strip()

        # fallback: Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼ ÐºÐ°Ðº Ñ‚ÐµÐºÑÑ‚ (ÐµÑÐ»Ð¸ Ð²Ð´Ñ€ÑƒÐ³ txt)
        return p.read_text(encoding="utf-8", errors="ignore").strip()

    except Exception as e:
        logger.warning(f"Failed to parse {path}: {e}")
        return ""


# ----------------------------
# Helpers: build context for a slide from SlideDocument
# ----------------------------
async def _build_slide_context(db: AsyncSession, slide_id: int, query: str) -> str:
    res = await db.execute(
        select(SlideDocument)
        .where(SlideDocument.slide_id == slide_id)
        .order_by(SlideDocument.id.asc())
    )
    docs = res.scalars().all()
    if not docs:
        return ""

    documents_for_index: list[dict] = []

    for d in docs:
        if d.parsed_text:
            text = d.parsed_text
        else:
            text = await _parse_text_from_path(d.storage_path)
            if text:
                d.parsed_text = text  # ÐºÐµÑˆÐ¸Ñ€ÑƒÐµÐ¼
        documents_for_index.append({"text": text, "metadata": {"filename": d.filename}})

    await db.commit()

    idx = DocumentIndex()
    idx.add_documents(documents_for_index)
    idx.build_index()

    hits = idx.search(query, k=5)
    context = "\n\n".join(f"[{source}]\n{content}" for (content, _kind, source) in hits if content)
    return context[:12000]


async def _get_latest_slide_content(db: AsyncSession, slide_id: int) -> SlideContent | None:
    res = await db.execute(
        select(SlideContent)
        .where(SlideContent.slide_id == slide_id)
        .order_by(desc(SlideContent.id))
        .limit(1)
    )
    return res.scalar_one_or_none()


# ----------------------------
# Jobs: export template (optional)
# ----------------------------
async def _resolve_project_template_path(db: AsyncSession, project_id: int) -> str | None:
    """
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¿ÑƒÑ‚ÑŒ Ðº pptx-ÑˆÐ°Ð±Ð»Ð¾Ð½Ñƒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° (ÐµÑÐ»Ð¸ Ð½Ð°Ð·Ð½Ð°Ñ‡ÐµÐ½).
    ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ Ð¾Ð±Ð° Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð°:
      1) relationship: Project.template
      2) FK: Project.template_id
    """
    # 1) Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¾ÐµÐºÑ‚ ÑÑ€Ð°Ð·Ñƒ Ñ template (ÐµÑÐ»Ð¸ relationship ÐµÑÑ‚ÑŒ)
    try:
        res = await db.execute(
            select(Project)
            .options(joinedload(Project.template))
            .where(Project.id == project_id)
        )
        project = res.scalar_one()
        tmpl = getattr(project, "template", None)
        if tmpl and getattr(tmpl, "storage_path", None):
            return tmpl.storage_path
    except Exception:
        # relationship Ð¼Ð¾Ð¶ÐµÑ‚ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¾Ð²Ð°Ñ‚ÑŒ â€” Ð¾Ðº, Ð¿Ð°Ð´Ð°ÐµÐ¼ Ð½Ð° fallback
        pass

    # 2) fallback: template_id -> Template
    res = await db.execute(select(Project).where(Project.id == project_id))
    project = res.scalar_one()

    template_id = getattr(project, "template_id", None)
    if not template_id:
        return None

    res = await db.execute(select(Template).where(Template.id == template_id))
    tmpl = res.scalar_one_or_none()
    if not tmpl:
        return None

    return getattr(tmpl, "storage_path", None)



# ----------------------------
# Job handlers
# ----------------------------
async def generate_slide_job(db: AsyncSession, job: Job) -> None:
    if job.slide_id is None:
        raise ValueError("Job.slide_id is required for generate_slide")

    slide = (await db.execute(select(Slide).where(Slide.id == job.slide_id))).scalar_one()
    project = (await db.execute(select(Project).where(Project.id == slide.project_id))).scalar_one()

    if not slide.prompt or not slide.prompt.strip():
        raise ValueError("Slide prompt is empty")

    job.progress = 10
    await db.commit()

    context_text = await _build_slide_context(db, slide.id, slide.prompt)

    job.progress = 30
    await db.commit()

    # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð·Ð°Ñ€Ð°Ð½ÐµÐµ
    generated_image_path = None
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð»Ð¸ ÑÑ‚Ð¾ Ð¿ÐµÑ€Ð²Ñ‹Ð¼ ÑÐ»Ð°Ð¹Ð´Ð¾Ð¼ (Ñ‚Ð¸Ñ‚ÑƒÐ»ÑŒÐ½Ñ‹Ð¹ ÑÐ»Ð°Ð¹Ð´)
    # Ð¸Ð»Ð¸ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ ÑÐ»Ð°Ð¹Ð´Ð° ÑƒÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ Ð½Ð° Ñ‚Ð¸Ñ‚ÑƒÐ»ÑŒÐ½Ñ‹Ð¹ ÑÐ»Ð°Ð¹Ð´
    is_first_slide = slide.position == 1
    title_lower = (slide.title or "").lower()
    title_keywords = ["Ñ‚Ð¸Ñ‚ÑƒÐ»ÑŒÐ½Ñ‹Ð¹", "Ñ‚Ð¸Ñ‚ÑƒÐ»", "Ð¾Ð±Ð»Ð¾Ð¶ÐºÐ°", "cover", "title slide", "Ð½Ð°Ñ‡Ð°Ð»Ð¾"]
    is_title_by_name = any(kw in title_lower for kw in title_keywords)
    
    # Ð•ÑÐ»Ð¸ ÑÑ‚Ð¾ Ð¿ÐµÑ€Ð²Ñ‹Ð¹ ÑÐ»Ð°Ð¹Ð´ Ð¸Ð»Ð¸ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ ÑƒÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ Ð½Ð° Ñ‚Ð¸Ñ‚ÑƒÐ»ÑŒÐ½Ñ‹Ð¹, Ð¿Ñ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ ÑƒÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ layout = "title"
    if is_first_slide or is_title_by_name:
        layout_type = "title"
        generated_text = ""  # Ð”Ð»Ñ Ñ‚Ð¸Ñ‚ÑƒÐ»ÑŒÐ½Ð¾Ð³Ð¾ ÑÐ»Ð°Ð¹Ð´Ð° Ð½Ðµ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚
    else:
        # Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¾Ñ‡ÐµÐ½ÑŒ Ð´Ð¾Ð»Ð³Ð¾Ð¹ Ð½Ð° CPU/GPU.
        # Ð§Ñ‚Ð¾Ð±Ñ‹ job Ð½Ðµ "Ð²Ð¸ÑÐµÐ»" Ð±ÐµÑÐºÐ¾Ð½ÐµÑ‡Ð½Ð¾ Ð² UI, Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸ÑŽ Ð² Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¼ Ð¿Ð¾Ñ‚Ð¾ÐºÐµ
        # Ð¸ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ ÐµÑ‘ Ð¿Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸.
        job.progress = 40
        await db.commit()

        # Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð° Ð¸Ð· ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸
        # ÐœÐ¾Ð¶Ð½Ð¾ Ð¿ÐµÑ€ÐµÐ¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ Ñ‡ÐµÑ€ÐµÐ· Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ LLM_GENERATION_TIMEOUT_SEC
        timeout_sec = settings.LLM_GENERATION_TIMEOUT_SEC

        try:
            logger.info(f"ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸ÑŽ ÑÐ»Ð°Ð¹Ð´Ð° (Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚: {timeout_sec}Ñ)")
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÑÐµÐ¼Ð°Ñ„Ð¾Ñ€ Ð´Ð»Ñ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð²Ñ‹Ð·Ð¾Ð²Ð¾Ð² Ð¼Ð¾Ð´ÐµÐ»Ð¸
            # ÐŸÐ¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ 2 Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¾Ð´Ð½Ð¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾
            if _llm_generation_semaphore:
                async with _llm_generation_semaphore:
                    out = await asyncio.wait_for(
                        asyncio.to_thread(
                            lambda: content_generator.generate_from_prompt(
                                user_prompt=slide.prompt,
                                context=context_text,
                                audience=str(project.audience_type),
                                visual_type=str(slide.visual_type),
                                max_chars=800,  # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ðµ ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð² Ð´Ð»Ñ ÑÐ»Ð°Ð¹Ð´Ð°
                            )
                        ),
                        timeout=timeout_sec
                    )
            else:
                # Ð•ÑÐ»Ð¸ ÑÐµÐ¼Ð°Ñ„Ð¾Ñ€ Ð½Ðµ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½, Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÐ¼ Ð±ÐµÐ· Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ð¹
                out = await asyncio.wait_for(
                    asyncio.to_thread(
                        lambda: content_generator.generate_from_prompt(
                            user_prompt=slide.prompt,
                            context=context_text,
                            audience=str(project.audience_type),
                            visual_type=str(slide.visual_type),
                            max_chars=800,  # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ðµ ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð² Ð´Ð»Ñ ÑÐ»Ð°Ð¹Ð´Ð°
                        )
                    ),
                    timeout=timeout_sec
                )
            generated_text = (out.get("content") or "").strip()
            layout_type = out.get("layout", "title_and_content")
        except asyncio.TimeoutError:
            error_msg = (
                f"Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ ({timeout_sec}Ñ). "
                "Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ ÑÐ»Ð°Ð¹Ð´Ð° Ð¿Ñ€ÐµÐ²Ñ‹ÑÐ¸Ð»Ð° Ð´Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ. "
                "ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÑƒÐ¼ÐµÐ½ÑŒÑˆÐ¸Ñ‚ÑŒ MAX_NEW_TOKENS Ð² Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ°Ñ… Ð¸Ð»Ð¸ ÑƒÐ²ÐµÐ»Ð¸Ñ‡Ð¸Ñ‚ÑŒ LLM_GENERATION_TIMEOUT_SEC."
            )
            logger.error(error_msg)
            raise TimeoutError(error_msg)
        
        # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ, ÐµÑÐ»Ð¸ Ñ‚Ð¸Ð¿ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ - image
        if str(slide.visual_type) == "image" and generated_text:
            job.progress = 60
            await db.commit()
            try:
                logger.info(f"Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð´Ð»Ñ ÑÐ»Ð°Ð¹Ð´Ð° {slide.id}")
                generated_image_path = await image_generator.generate_image_async(
                    prompt=generated_text,
                )
                if generated_image_path:
                    logger.info(f"Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾: {generated_image_path}")
            except Exception as e:
                logger.warning(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ: {e}")
                # ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ Ð±ÐµÐ· Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ

    job.progress = 70
    await db.commit()

    sc = SlideContent(slide_id=slide.id)
    _sc_set_text(sc, generated_text)
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾ Ð¼Ð°ÐºÐµÑ‚Ðµ, Ñ‚Ð¸Ð¿Ðµ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð¸ Ð¿ÑƒÑ‚Ð¸ Ðº Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑŽ
    sc.llm_meta = {
        "layout": layout_type,
        "visual_type": str(slide.visual_type),
    }
    if generated_image_path:
        sc.llm_meta["generated_image_path"] = generated_image_path

    # ÐµÑÐ»Ð¸ Ñƒ Ñ‚ÐµÐ±Ñ ÐµÑÑ‚ÑŒ version â€” ÑƒÐ²ÐµÐ»Ð¸Ñ‡Ð¸Ð¼
    if hasattr(sc, "version"):
        res = await db.execute(
            select(SlideContent)
            .where(SlideContent.slide_id == slide.id)
            .order_by(desc(SlideContent.version))
            .limit(1)
        )
        last = res.scalar_one_or_none()
        sc.version = (last.version + 1) if last else 1

    db.add(sc)
    await db.commit()
    
    # Ð¡Ñ‚Ð°Ñ‚ÑƒÑ ÑÐ»Ð°Ð¹Ð´Ð° Ð±ÑƒÐ´ÐµÑ‚ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½ Ð² _set_job_done() Ð¿Ð¾ÑÐ»Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ job


async def export_project_pptx_job(db, job: Job):
    project = (await db.execute(select(Project).where(Project.id == job.project_id))).scalar_one()

    slides = (await db.execute(
        select(Slide)
        .where(Slide.project_id == project.id)
        .order_by(Slide.position.asc())
    )).scalars().all()

    # ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÐµÐ½
    template_path = await _resolve_project_template_path(db, project.id)

    # ÐµÑÐ»Ð¸ ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð½Ð°Ð·Ð½Ð°Ñ‡ÐµÐ½, Ð½Ð¾ Ñ„Ð°Ð¹Ð»Ð° Ð½ÐµÑ‚ â€” Ð»ÑƒÑ‡ÑˆÐµ ÑÐ²Ð½Ð¾ ÑƒÐ¿Ð°ÑÑ‚ÑŒ (Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð¼Ð¾Ð»Ñ‡Ð° Ð´ÐµÐ»Ð°Ñ‚ÑŒ "Ð±ÐµÐ· ÑˆÐ°Ð±Ð»Ð¾Ð½Ð°")
    if template_path and not Path(template_path).exists():
        raise FileNotFoundError(f"Template file not found: {template_path}")

    builder = PresentationBuilder(template_path=template_path)

    export_slides: list[SlideExport] = []
    for i, s in enumerate(slides, start=1):
        sc = await _get_latest_slide_content(db, s.id)
        content_text = _sc_get_text(sc)
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾ Ð¼Ð°ÐºÐµÑ‚Ðµ Ð¸Ð· llm_meta
        layout_type = "title_and_content"
        images_list = []
        if sc and sc.llm_meta:
            if "layout" in sc.llm_meta:
                layout_type = sc.llm_meta["layout"]
            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿ÑƒÑ‚ÑŒ Ðº ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¼Ñƒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑŽ, ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ
            if "generated_image_path" in sc.llm_meta:
                image_path = sc.llm_meta["generated_image_path"]
                if Path(image_path).exists():
                    images_list.append(image_path)
        
        export_slides.append(SlideExport(
            title=s.title or f"Slide {i}", 
            content=content_text, 
            images=images_list,
            layout=layout_type,
            visual_type=str(s.visual_type)
        ))

    for se in export_slides:
        builder.add_slide(
            slide_type=se.layout if hasattr(se, "layout") else "content",
            title=se.title, 
            content=se.content, 
            images=se.images,
            visual_type=se.visual_type if hasattr(se, "visual_type") else "text"
        )

    data = builder.save_to_bytes().getvalue()

    safe_title = (project.title or "presentation").strip().replace(" ", "_")
    filename = f"{safe_title}_{uuid.uuid4().hex}.pptx"
    out_path = STORAGE_DIR / filename
    out_path.write_bytes(data)

    out_file = File(
        user_id=job.user_id,
        project_id=project.id,
        kind=FileKind.export_pptx,
        filename=filename,
        storage_path=str(out_path),
        size_bytes=len(data),
    )
    db.add(out_file)
    await db.commit()
    await db.refresh(out_file)

    job.result_file_id = out_file.id
    await db.commit()

async def export_project_pdf_job(db, job: Job):
    project = (await db.execute(select(Project).where(Project.id == job.project_id))).scalar_one()

    slides = (await db.execute(
        select(Slide)
        .where(Slide.project_id == project.id)
        .order_by(Slide.position.asc())
    )).scalars().all()

    export_slides: list[SlideExport] = []
    for i, s in enumerate(slides, start=1):
        sc = await _get_latest_slide_content(db, s.id)
        content_text = _sc_get_text(sc)
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾ Ð¼Ð°ÐºÐµÑ‚Ðµ Ð¸Ð· llm_meta
        layout_type = "title_and_content"
        images_list = []
        if sc and sc.llm_meta:
            if "layout" in sc.llm_meta:
                layout_type = sc.llm_meta["layout"]
            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿ÑƒÑ‚ÑŒ Ðº ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¼Ñƒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑŽ, ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ
            if "generated_image_path" in sc.llm_meta:
                image_path = sc.llm_meta["generated_image_path"]
                if Path(image_path).exists():
                    images_list.append(image_path)
        
        export_slides.append(SlideExport(
            title=s.title or f"Slide {i}", 
            content=content_text, 
            images=images_list,
            layout=layout_type,
            visual_type=str(s.visual_type)
        ))

    pdf_bytes = slides_to_pdf_bytes(export_slides, audience=str(project.audience_type))

    safe_title = (project.title or "presentation").strip().replace(" ", "_")
    filename = f"{safe_title}_{uuid.uuid4().hex}.pdf"
    out_path = STORAGE_DIR / filename
    out_path.write_bytes(pdf_bytes)

    out_file = File(
        user_id=job.user_id,
        project_id=project.id,
        kind=FileKind.export_pdf,
        filename=filename,
        storage_path=str(out_path),
        size_bytes=len(pdf_bytes),
    )
    db.add(out_file)
    await db.commit()
    await db.refresh(out_file)

    job.result_file_id = out_file.id
    await db.commit()


async def handle_job(db: AsyncSession, job: Job) -> None:
    if job.type == JobType.generate_slide:
        await generate_slide_job(db, job)
        return

    if job.type == JobType.export_pptx:
        await export_project_pptx_job(db, job)
        return

    if job.type == JobType.export_pdf:
        await export_project_pdf_job(db, job)
        return

    raise NotImplementedError(f"Job type not supported yet: {job.type}")


# ----------------------------
# Job state helpers
# ----------------------------
async def _fetch_one_queued_job(db: AsyncSession) -> Optional[Job]:
    q = (
        select(Job)
        .where(Job.status == JobStatus.queued)
        .order_by(Job.id.asc())
        .with_for_update(skip_locked=True)
        .limit(1)
    )
    res = await db.execute(q)
    return res.scalar_one_or_none()


async def _fetch_multiple_queued_jobs(db: AsyncSession, limit: int) -> List[Job]:
    """ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð·Ð°Ð´Ð°Ñ‡ Ð¸Ð· Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð¸ Ð´Ð»Ñ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸"""
    q = (
        select(Job)
        .where(Job.status == JobStatus.queued)
        .order_by(Job.id.asc())
        .with_for_update(skip_locked=True)
        .limit(limit)
    )
    res = await db.execute(q)
    return list(res.scalars().all())


async def _set_job_running(db: AsyncSession, job: Job) -> None:
    job.status = JobStatus.running
    job.progress = 1
    job.error_message = None
    await db.commit()


async def _set_job_done(db: AsyncSession, job: Job) -> None:
    job.status = JobStatus.done
    job.progress = 100
    
    # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚ÑƒÑ ÑÐ»Ð°Ð¹Ð´Ð° Ð½Ð° ready Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ð¾ÑÐ»Ðµ Ñ‚Ð¾Ð³Ð¾, ÐºÐ°Ðº job Ð¿Ð¾Ð¼ÐµÑ‡ÐµÐ½ ÐºÐ°Ðº done
    # Ð­Ñ‚Ð¾ Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€ÑƒÐµÑ‚, Ñ‡Ñ‚Ð¾ "Ð“Ð¾Ñ‚Ð¾Ð²" Ð¿Ð¾ÑÐ²Ð¸Ñ‚ÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ð¾ÑÐ»Ðµ Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ (Ð¿Ð¾ÑÐ»Ðµ Ð»Ð¾Ð³Ð° "Job done")
    if job.type == JobType.generate_slide and job.slide_id is not None:
        slide = (await db.execute(select(Slide).where(Slide.id == job.slide_id))).scalar_one_or_none()
        if slide is not None and hasattr(slide, "status"):
            slide.status = SlideStatus.ready
    
    await db.commit()


async def _set_job_failed(db: AsyncSession, job: Job, exc: Exception) -> None:
    job.status = JobStatus.error
    job.progress = 100
    job.error_message = str(exc)
    # ÐµÑÐ»Ð¸ ÑÑ‚Ð¾ job Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ â€” Ð¾Ñ‚Ð¼ÐµÑ‚Ð¸Ð¼ Ð¸ ÑÐ»Ð°Ð¹Ð´ ÐºÐ°Ðº error, Ñ‡Ñ‚Ð¾Ð±Ñ‹ UI Ð¿ÐµÑ€ÐµÑÑ‚Ð°Ð» ÐºÑ€ÑƒÑ‚Ð¸Ñ‚ÑŒÑÑ
    try:
        if job.slide_id is not None:
            slide = (await db.execute(select(Slide).where(Slide.id == job.slide_id))).scalar_one_or_none()
            if slide is not None and hasattr(slide, "status"):
                slide.status = SlideStatus.error
    except Exception:
        # Ð½Ðµ Ð¼ÐµÑˆÐ°ÐµÐ¼ Ð¿Ð°Ð´ÐµÐ½Ð¸ÑŽ job
        pass
    await db.commit()


# ----------------------------
# Worker task handler
# ----------------------------
async def _process_job(job_id: int) -> None:
    """ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð¾Ð´Ð½Ñƒ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Ð² Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¹ ÑÐµÑÑÐ¸Ð¸ Ð‘Ð”"""
    async with AsyncSessionLocal() as db:
        try:
            # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Ð¸Ð· Ð‘Ð” Ð² Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¹ ÑÐµÑÑÐ¸Ð¸
            job = (await db.execute(select(Job).where(Job.id == job_id))).scalar_one_or_none()
            if not job:
                logger.warning(f"Job {job_id} not found")
                return
            
            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð·Ð°Ð´Ð°Ñ‡Ð¸
            await _set_job_running(db, job)
            
            logger.info(f"âž¡ï¸ Processing job id={job.id} type={job.type}")
            
            # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð·Ð°Ð´Ð°Ñ‡Ñƒ (ÑÐµÐ¼Ð°Ñ„Ð¾Ñ€ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÑÐµÑ‚ÑÑ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ handle_job Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÑÐ»Ð°Ð¹Ð´Ð¾Ð²)
            await handle_job(db, job)
            
            # ÐžÑ‚Ð¼ÐµÑ‡Ð°ÐµÐ¼ ÐºÐ°Ðº Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð½ÑƒÑŽ
            await _set_job_done(db, job)
            logger.info(f"âœ… Job done id={job.id}")
        except Exception as e:
            logger.exception(f"âŒ Job failed id={job_id}: {e}")
            try:
                # ÐŸÐµÑ€ÐµÐ·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Ð´Ð»Ñ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ ÑÑ‚Ð°Ñ‚ÑƒÑÐ°
                job = (await db.execute(select(Job).where(Job.id == job_id))).scalar_one_or_none()
                if job:
                    await _set_job_failed(db, job, e)
            except Exception as db_error:
                logger.error(f"Failed to update job status in DB: {db_error}")


# ----------------------------
# Worker loop
# ----------------------------
async def worker_loop() -> None:
    global _llm_generation_semaphore
    
    parallel_jobs = settings.WORKER_PARALLEL_JOBS
    # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ ÑÐµÐ¼Ð°Ñ„Ð¾Ñ€ Ð´Ð»Ñ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð²Ñ‹Ð·Ð¾Ð²Ð¾Ð² Ð¼Ð¾Ð´ÐµÐ»Ð¸
    # ÐŸÐ¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ 2 Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¾Ð´Ð½Ð¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾
    llm_parallel_limit = int(os.getenv("LLM_PARALLEL_GENERATIONS", "2"))
    _llm_generation_semaphore = asyncio.Semaphore(llm_parallel_limit)
    
    logger.info(f"ðŸ§µ Worker started (parallel jobs: {parallel_jobs}, LLM parallel limit: {llm_parallel_limit})")
    
    active_tasks: set[asyncio.Task] = set()

    while True:
        # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð½Ñ‹Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸
        active_tasks = {t for t in active_tasks if not t.done()}
        
        # Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ð·Ð°Ð´Ð°Ñ‡ Ð¼Ð¾Ð¶ÐµÐ¼ Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾
        available_slots = parallel_jobs - len(active_tasks)
        
        if available_slots > 0:
            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¸Ð· Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð¸
            async with AsyncSessionLocal() as db:
                jobs = await _fetch_multiple_queued_jobs(db, limit=available_slots)
            
            # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÑƒ Ð·Ð°Ð´Ð°Ñ‡ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾
            for job in jobs:
                task = asyncio.create_task(_process_job(job.id))
                active_tasks.add(task)
                logger.info(f"ðŸš€ Started parallel processing job id={job.id}")
        
        # Ð–Ð´ÐµÐ¼ Ð½ÐµÐ¼Ð½Ð¾Ð³Ð¾ Ð¿ÐµÑ€ÐµÐ´ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ¹ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¾Ð¹
        if not active_tasks:
            await asyncio.sleep(POLL_INTERVAL_SEC)
        else:
            # Ð–Ð´ÐµÐ¼ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ Ñ…Ð¾Ñ‚Ñ Ð±Ñ‹ Ð¾Ð´Ð½Ð¾Ð¹ Ð·Ð°Ð´Ð°Ñ‡Ð¸
            done, pending = await asyncio.wait(active_tasks, return_when=asyncio.FIRST_COMPLETED, timeout=POLL_INTERVAL_SEC)
            active_tasks = pending


def main() -> None:
    asyncio.run(worker_loop())


if __name__ == "__main__":
    main()

